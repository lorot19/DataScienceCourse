{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a576b1f1-459f-405d-b625-9d9455234c16",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /Users/tomaslorincfpt/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /Users/tomaslorincfpt/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package omw-1.4 to\n",
      "[nltk_data]     /Users/tomaslorincfpt/nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# import libraries\n",
    "import sys\n",
    "import re\n",
    "import pandas as pd\n",
    "from sqlalchemy import create_engine\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.multioutput import MultiOutputClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "import pickle\n",
    "\n",
    "nltk.download(['punkt', 'wordnet', 'omw-1.4'])\n",
    "\n",
    "# define regex characters\n",
    "url_regex = 'http[s]?://(?:[a-zA-Z]|[0-9]|[$-_@.&+]|[!*\\(\\),]|(?:%[0-9a-fA-F][0-9a-fA-F]))+'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d9efbf60-d0ef-4597-8be7-6726f4572a14",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(text):\n",
    "    \"\"\"\n",
    "    Function which tokenize message using regular expressions\n",
    "    :param text: String containing message\n",
    "    :return: clean_tokens: list of words containing tokenized and cleaned message\n",
    "    \"\"\"\n",
    "    # get list of all urls using regex\n",
    "    detected_urls = re.findall(url_regex, text)\n",
    "    # replace each url in text string with placeholder\n",
    "    for url in detected_urls:\n",
    "        text = text.replace(url, \"urlplaceholder\")\n",
    "    # tokenize text\n",
    "    tokens = word_tokenize(text)\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    # iterate through each token\n",
    "    clean_tokens = []\n",
    "    for tok in tokens:\n",
    "        # lemmatize, normalize case, and remove leading/trailing white space\n",
    "        clean_tok = lemmatizer.lemmatize(tok).lower().strip()\n",
    "        clean_tokens.append(clean_tok)\n",
    "    return clean_tokens\n",
    "\n",
    "def display_results(cv, y_test, y_pred, labels):\n",
    "    \"\"\"\n",
    "    This function visualise trained model\n",
    "    :param cv: Any\n",
    "    :param y_test: Any\n",
    "    :param y_pred: Any\n",
    "    :param labels: Any\n",
    "    :return: none\n",
    "    \"\"\"\n",
    "    accuracy = (y_pred == y_test).mean()\n",
    "    print(\"Labels:\", labels)\n",
    "    print(\"Accuracy:\", accuracy)\n",
    "    print(\"\\nBest Parameters:\", cv.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e3c51093-d650-4989-aab4-cefca004fdc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data\n",
    "engine = create_engine('sqlite:///moviesdata.db')\n",
    "df = pd.read_sql_table(table_name='name', con=engine)\n",
    "X = df['title']\n",
    "Y = df[df.columns].drop(['title'], axis = 1)\n",
    "\n",
    "Y = Y.astype(int)\n",
    "categories = Y.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f90810c7-94e1-4ca1-9fe8-197454139485",
   "metadata": {},
   "outputs": [],
   "source": [
    "# split data\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8c7ca764-7174-4d04-bc3b-90afd04184cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# build model\n",
    "pipeline = Pipeline([\n",
    "    ('vect', CountVectorizer(tokenizer=tokenize)),\n",
    "    ('Tfidf', TfidfTransformer()),\n",
    "    ('clf', MultiOutputClassifier(RandomForestClassifier()))])\n",
    "parameters = {'clf__estimator__n_estimators': [3]}\n",
    "\n",
    "model = GridSearchCV(pipeline, param_grid=parameters, verbose=3, n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "68606834-c4e9-42e3-bde3-96d7d1e89ecf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(estimator=Pipeline(steps=[('vect',\n",
       "                                        CountVectorizer(tokenizer=<function tokenize at 0x169ef69d0>)),\n",
       "                                       ('Tfidf', TfidfTransformer()),\n",
       "                                       ('clf',\n",
       "                                        MultiOutputClassifier(estimator=RandomForestClassifier()))]),\n",
       "             n_jobs=-1, param_grid={'clf__estimator__n_estimators': [3]},\n",
       "             verbose=3)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fit model\n",
    "model.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b83dea50-0f87-4a51-8135-3e696f3c12cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labels: Index(['drama', 'fantasy', 'war', 'comedy', 'thriller', 'crime', 'romance',\n",
      "       'action', 'western', 'history', 'documentation', 'music', 'horror',\n",
      "       'scifi', 'animation', 'family', 'reality', 'sport', 'european'],\n",
      "      dtype='object')\n",
      "Accuracy: drama            0.611111\n",
      "fantasy          0.877193\n",
      "war              0.965887\n",
      "comedy           0.597466\n",
      "thriller         0.724172\n",
      "crime            0.809942\n",
      "romance          0.815789\n",
      "action           0.774854\n",
      "western          0.995127\n",
      "history          0.955166\n",
      "documentation    0.813840\n",
      "music            0.939571\n",
      "horror           0.883041\n",
      "scifi            0.873294\n",
      "animation        0.899610\n",
      "family           0.851852\n",
      "reality          0.953216\n",
      "sport            0.966862\n",
      "european         0.907407\n",
      "dtype: float64\n",
      "\n",
      "Best Parameters: {'clf__estimator__n_estimators': 3}\n"
     ]
    }
   ],
   "source": [
    "# display results\n",
    "y_pred = model.predict(X_test)\n",
    "display_results(model, Y_test, y_pred, categories)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "49856b78-6781-43ce-a7c1-1beaf13ff3f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END ....clf__estimator__n_estimators=3;, score=0.061 total time=   1.6s\n",
      "[CV 3/5] END ....clf__estimator__n_estimators=3;, score=0.041 total time=   1.7s\n",
      "[CV 5/5] END ....clf__estimator__n_estimators=3;, score=0.076 total time=   1.7s\n",
      "[CV 4/5] END ....clf__estimator__n_estimators=3;, score=0.071 total time=   1.8s\n",
      "[CV 2/5] END ....clf__estimator__n_estimators=3;, score=0.051 total time=   1.7s\n"
     ]
    }
   ],
   "source": [
    "#save model\n",
    "with open('netflix_model.pkl', 'wb') as f:\n",
    "    pickle.dump(model, f)\n",
    "pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f947645a-def3-4bdc-b786-2da4080261b2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
